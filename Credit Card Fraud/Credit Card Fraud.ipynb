{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.537294e-16  7.959909e-16  5.367590e-16  4.458112e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0: Not Fraud; 1: Fraud\n",
    "df.Class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although decision tree, random forest, and naives bayes do not require scaling of data, we shall do so for ease of reusing data points for training and testing of other models â€“ knn, logistic regression and support vector classification.    \n",
    "Also making assumption data is follows normal distribution by using StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = scaler.fit_transform(df.drop(['Time', 'Amount', 'Class'], axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = pd.DataFrame(scaled, columns = df.columns[1:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([df['Time'], df_scaled, df['Amount']], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.694242</td>\n",
       "      <td>-0.044075</td>\n",
       "      <td>1.672773</td>\n",
       "      <td>0.973366</td>\n",
       "      <td>-0.245117</td>\n",
       "      <td>0.347068</td>\n",
       "      <td>0.193679</td>\n",
       "      <td>0.082637</td>\n",
       "      <td>0.331128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.326118</td>\n",
       "      <td>-0.024923</td>\n",
       "      <td>0.382854</td>\n",
       "      <td>-0.176911</td>\n",
       "      <td>0.110507</td>\n",
       "      <td>0.246585</td>\n",
       "      <td>-0.392170</td>\n",
       "      <td>0.330892</td>\n",
       "      <td>-0.063781</td>\n",
       "      <td>149.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.608496</td>\n",
       "      <td>0.161176</td>\n",
       "      <td>0.109797</td>\n",
       "      <td>0.316523</td>\n",
       "      <td>0.043483</td>\n",
       "      <td>-0.061820</td>\n",
       "      <td>-0.063700</td>\n",
       "      <td>0.071253</td>\n",
       "      <td>-0.232494</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089611</td>\n",
       "      <td>-0.307377</td>\n",
       "      <td>-0.880077</td>\n",
       "      <td>0.162201</td>\n",
       "      <td>-0.561131</td>\n",
       "      <td>0.320694</td>\n",
       "      <td>0.261069</td>\n",
       "      <td>-0.022256</td>\n",
       "      <td>0.044608</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.693500</td>\n",
       "      <td>-0.811578</td>\n",
       "      <td>1.169468</td>\n",
       "      <td>0.268231</td>\n",
       "      <td>-0.364572</td>\n",
       "      <td>1.351454</td>\n",
       "      <td>0.639776</td>\n",
       "      <td>0.207373</td>\n",
       "      <td>-1.378675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.680975</td>\n",
       "      <td>0.337632</td>\n",
       "      <td>1.063358</td>\n",
       "      <td>1.456320</td>\n",
       "      <td>-1.138092</td>\n",
       "      <td>-0.628537</td>\n",
       "      <td>-0.288447</td>\n",
       "      <td>-0.137137</td>\n",
       "      <td>-0.181021</td>\n",
       "      <td>378.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.493325</td>\n",
       "      <td>-0.112169</td>\n",
       "      <td>1.182516</td>\n",
       "      <td>-0.609727</td>\n",
       "      <td>-0.007469</td>\n",
       "      <td>0.936150</td>\n",
       "      <td>0.192071</td>\n",
       "      <td>0.316018</td>\n",
       "      <td>-1.262503</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.269855</td>\n",
       "      <td>-0.147443</td>\n",
       "      <td>0.007267</td>\n",
       "      <td>-0.304777</td>\n",
       "      <td>-1.941027</td>\n",
       "      <td>1.241904</td>\n",
       "      <td>-0.460217</td>\n",
       "      <td>0.155396</td>\n",
       "      <td>0.186189</td>\n",
       "      <td>123.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.591330</td>\n",
       "      <td>0.531541</td>\n",
       "      <td>1.021412</td>\n",
       "      <td>0.284655</td>\n",
       "      <td>-0.295015</td>\n",
       "      <td>0.071999</td>\n",
       "      <td>0.479302</td>\n",
       "      <td>-0.226510</td>\n",
       "      <td>0.744326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.529939</td>\n",
       "      <td>-0.012839</td>\n",
       "      <td>1.100011</td>\n",
       "      <td>-0.220123</td>\n",
       "      <td>0.233250</td>\n",
       "      <td>-0.395202</td>\n",
       "      <td>1.041611</td>\n",
       "      <td>0.543620</td>\n",
       "      <td>0.651816</td>\n",
       "      <td>69.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-6.065842</td>\n",
       "      <td>6.099286</td>\n",
       "      <td>-6.486245</td>\n",
       "      <td>-1.459641</td>\n",
       "      <td>-3.886611</td>\n",
       "      <td>-1.956690</td>\n",
       "      <td>-3.975628</td>\n",
       "      <td>6.116573</td>\n",
       "      <td>1.742559</td>\n",
       "      <td>...</td>\n",
       "      <td>1.914365</td>\n",
       "      <td>0.290602</td>\n",
       "      <td>0.154146</td>\n",
       "      <td>1.624574</td>\n",
       "      <td>-0.841000</td>\n",
       "      <td>2.756320</td>\n",
       "      <td>0.518500</td>\n",
       "      <td>2.337901</td>\n",
       "      <td>2.495529</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.374121</td>\n",
       "      <td>-0.033356</td>\n",
       "      <td>1.342145</td>\n",
       "      <td>-0.521651</td>\n",
       "      <td>0.629040</td>\n",
       "      <td>0.794446</td>\n",
       "      <td>0.019667</td>\n",
       "      <td>0.246886</td>\n",
       "      <td>0.532299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077330</td>\n",
       "      <td>0.291625</td>\n",
       "      <td>1.273781</td>\n",
       "      <td>0.019958</td>\n",
       "      <td>-1.677920</td>\n",
       "      <td>-1.163726</td>\n",
       "      <td>-0.819647</td>\n",
       "      <td>0.169641</td>\n",
       "      <td>-0.162164</td>\n",
       "      <td>24.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>0.980024</td>\n",
       "      <td>-0.182434</td>\n",
       "      <td>-2.143205</td>\n",
       "      <td>-0.393984</td>\n",
       "      <td>1.905833</td>\n",
       "      <td>2.275262</td>\n",
       "      <td>-0.239939</td>\n",
       "      <td>0.593140</td>\n",
       "      <td>0.393630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.315913</td>\n",
       "      <td>0.796788</td>\n",
       "      <td>-0.060053</td>\n",
       "      <td>1.056944</td>\n",
       "      <td>0.509797</td>\n",
       "      <td>-0.181182</td>\n",
       "      <td>0.011037</td>\n",
       "      <td>-0.080467</td>\n",
       "      <td>67.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.122755</td>\n",
       "      <td>0.321250</td>\n",
       "      <td>0.463320</td>\n",
       "      <td>0.487192</td>\n",
       "      <td>-0.273836</td>\n",
       "      <td>0.468155</td>\n",
       "      <td>-0.554672</td>\n",
       "      <td>0.568631</td>\n",
       "      <td>0.356887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165300</td>\n",
       "      <td>0.361112</td>\n",
       "      <td>1.102451</td>\n",
       "      <td>-0.261503</td>\n",
       "      <td>0.203428</td>\n",
       "      <td>-1.091855</td>\n",
       "      <td>1.133635</td>\n",
       "      <td>0.269604</td>\n",
       "      <td>0.316687</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.272331</td>\n",
       "      <td>-0.114899</td>\n",
       "      <td>0.463866</td>\n",
       "      <td>-0.357570</td>\n",
       "      <td>-0.009089</td>\n",
       "      <td>-0.487602</td>\n",
       "      <td>1.274769</td>\n",
       "      <td>-0.347176</td>\n",
       "      <td>0.442532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.496739</td>\n",
       "      <td>0.355411</td>\n",
       "      <td>0.886149</td>\n",
       "      <td>0.603365</td>\n",
       "      <td>0.014526</td>\n",
       "      <td>-0.908631</td>\n",
       "      <td>-1.696853</td>\n",
       "      <td>-0.005984</td>\n",
       "      <td>0.041350</td>\n",
       "      <td>217.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0            0.0 -0.694242 -0.044075  1.672773  0.973366 -0.245117  0.347068   \n",
       "1            0.0  0.608496  0.161176  0.109797  0.316523  0.043483 -0.061820   \n",
       "2            1.0 -0.693500 -0.811578  1.169468  0.268231 -0.364572  1.351454   \n",
       "3            1.0 -0.493325 -0.112169  1.182516 -0.609727 -0.007469  0.936150   \n",
       "4            2.0 -0.591330  0.531541  1.021412  0.284655 -0.295015  0.071999   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "284802  172786.0 -6.065842  6.099286 -6.486245 -1.459641 -3.886611 -1.956690   \n",
       "284803  172787.0 -0.374121 -0.033356  1.342145 -0.521651  0.629040  0.794446   \n",
       "284804  172788.0  0.980024 -0.182434 -2.143205 -0.393984  1.905833  2.275262   \n",
       "284805  172788.0 -0.122755  0.321250  0.463320  0.487192 -0.273836  0.468155   \n",
       "284806  172792.0 -0.272331 -0.114899  0.463866 -0.357570 -0.009089 -0.487602   \n",
       "\n",
       "              V7        V8        V9  ...       V20       V21       V22  \\\n",
       "0       0.193679  0.082637  0.331128  ...  0.326118 -0.024923  0.382854   \n",
       "1      -0.063700  0.071253 -0.232494  ... -0.089611 -0.307377 -0.880077   \n",
       "2       0.639776  0.207373 -1.378675  ...  0.680975  0.337632  1.063358   \n",
       "3       0.192071  0.316018 -1.262503  ... -0.269855 -0.147443  0.007267   \n",
       "4       0.479302 -0.226510  0.744326  ...  0.529939 -0.012839  1.100011   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "284802 -3.975628  6.116573  1.742559  ...  1.914365  0.290602  0.154146   \n",
       "284803  0.019667  0.246886  0.532299  ...  0.077330  0.291625  1.273781   \n",
       "284804 -0.239939  0.593140  0.393630  ...  0.001811  0.315913  0.796788   \n",
       "284805 -0.554672  0.568631  0.356887  ...  0.165300  0.361112  1.102451   \n",
       "284806  1.274769 -0.347176  0.442532  ...  0.496739  0.355411  0.886149   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \n",
       "0      -0.176911  0.110507  0.246585 -0.392170  0.330892 -0.063781  149.62  \n",
       "1       0.162201 -0.561131  0.320694  0.261069 -0.022256  0.044608    2.69  \n",
       "2       1.456320 -1.138092 -0.628537 -0.288447 -0.137137 -0.181021  378.66  \n",
       "3      -0.304777 -1.941027  1.241904 -0.460217  0.155396  0.186189  123.50  \n",
       "4      -0.220123  0.233250 -0.395202  1.041611  0.543620  0.651816   69.99  \n",
       "...          ...       ...       ...       ...       ...       ...     ...  \n",
       "284802  1.624574 -0.841000  2.756320  0.518500  2.337901  2.495529    0.77  \n",
       "284803  0.019958 -1.677920 -1.163726 -0.819647  0.169641 -0.162164   24.79  \n",
       "284804 -0.060053  1.056944  0.509797 -0.181182  0.011037 -0.080467   67.88  \n",
       "284805 -0.261503  0.203428 -1.091855  1.133635  0.269604  0.316687   10.00  \n",
       "284806  0.603365  0.014526 -0.908631 -1.696853 -0.005984  0.041350  217.00  \n",
       "\n",
       "[284807 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>-8.157366e-16</td>\n",
       "      <td>3.154853e-17</td>\n",
       "      <td>-4.409878e-15</td>\n",
       "      <td>-6.734811e-16</td>\n",
       "      <td>-2.874435e-16</td>\n",
       "      <td>4.168992e-16</td>\n",
       "      <td>-8.767997e-16</td>\n",
       "      <td>-2.423604e-16</td>\n",
       "      <td>3.078727e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>2.754870e-16</td>\n",
       "      <td>1.685077e-17</td>\n",
       "      <td>1.478472e-15</td>\n",
       "      <td>-6.797197e-16</td>\n",
       "      <td>1.234659e-16</td>\n",
       "      <td>-7.659279e-16</td>\n",
       "      <td>3.247603e-16</td>\n",
       "      <td>-2.953495e-18</td>\n",
       "      <td>5.401572e-17</td>\n",
       "      <td>88.349619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>250.120109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.879855e+01</td>\n",
       "      <td>-4.403529e+01</td>\n",
       "      <td>-3.187173e+01</td>\n",
       "      <td>-4.013919e+00</td>\n",
       "      <td>-8.240810e+01</td>\n",
       "      <td>-1.963606e+01</td>\n",
       "      <td>-3.520940e+01</td>\n",
       "      <td>-6.130252e+01</td>\n",
       "      <td>-1.222802e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.069146e+01</td>\n",
       "      <td>-4.741907e+01</td>\n",
       "      <td>-1.506565e+01</td>\n",
       "      <td>-7.175446e+01</td>\n",
       "      <td>-4.683638e+00</td>\n",
       "      <td>-1.975033e+01</td>\n",
       "      <td>-5.401098e+00</td>\n",
       "      <td>-5.590660e+01</td>\n",
       "      <td>-4.674612e+01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-4.698918e-01</td>\n",
       "      <td>-3.624707e-01</td>\n",
       "      <td>-5.872142e-01</td>\n",
       "      <td>-5.993788e-01</td>\n",
       "      <td>-5.010686e-01</td>\n",
       "      <td>-5.766822e-01</td>\n",
       "      <td>-4.478860e-01</td>\n",
       "      <td>-1.746805e-01</td>\n",
       "      <td>-5.853631e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.746334e-01</td>\n",
       "      <td>-3.109433e-01</td>\n",
       "      <td>-7.473476e-01</td>\n",
       "      <td>-2.591784e-01</td>\n",
       "      <td>-5.854676e-01</td>\n",
       "      <td>-6.084001e-01</td>\n",
       "      <td>-6.780717e-01</td>\n",
       "      <td>-1.755053e-01</td>\n",
       "      <td>-1.604440e-01</td>\n",
       "      <td>5.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>9.245351e-03</td>\n",
       "      <td>3.965683e-02</td>\n",
       "      <td>1.186124e-01</td>\n",
       "      <td>-1.401724e-02</td>\n",
       "      <td>-3.936682e-02</td>\n",
       "      <td>-2.058046e-01</td>\n",
       "      <td>3.241723e-02</td>\n",
       "      <td>1.871982e-02</td>\n",
       "      <td>-4.681169e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.104705e-02</td>\n",
       "      <td>-4.009429e-02</td>\n",
       "      <td>9.345377e-03</td>\n",
       "      <td>-1.792420e-02</td>\n",
       "      <td>6.765678e-02</td>\n",
       "      <td>3.183240e-02</td>\n",
       "      <td>-1.081217e-01</td>\n",
       "      <td>3.325174e-03</td>\n",
       "      <td>3.406368e-02</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>6.716939e-01</td>\n",
       "      <td>4.867202e-01</td>\n",
       "      <td>6.774569e-01</td>\n",
       "      <td>5.250082e-01</td>\n",
       "      <td>4.433465e-01</td>\n",
       "      <td>2.991625e-01</td>\n",
       "      <td>4.611107e-01</td>\n",
       "      <td>2.740785e-01</td>\n",
       "      <td>5.435305e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.725733e-01</td>\n",
       "      <td>2.537392e-01</td>\n",
       "      <td>7.283360e-01</td>\n",
       "      <td>2.364319e-01</td>\n",
       "      <td>7.257153e-01</td>\n",
       "      <td>6.728006e-01</td>\n",
       "      <td>4.996663e-01</td>\n",
       "      <td>2.255648e-01</td>\n",
       "      <td>2.371526e-01</td>\n",
       "      <td>77.165000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>1.253351e+00</td>\n",
       "      <td>1.335775e+01</td>\n",
       "      <td>6.187993e+00</td>\n",
       "      <td>1.191874e+01</td>\n",
       "      <td>2.521413e+01</td>\n",
       "      <td>5.502015e+01</td>\n",
       "      <td>9.747824e+01</td>\n",
       "      <td>1.675153e+01</td>\n",
       "      <td>1.419494e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>5.113464e+01</td>\n",
       "      <td>3.703471e+01</td>\n",
       "      <td>1.447304e+01</td>\n",
       "      <td>3.607668e+01</td>\n",
       "      <td>7.569684e+00</td>\n",
       "      <td>1.442532e+01</td>\n",
       "      <td>7.293975e+00</td>\n",
       "      <td>7.831940e+01</td>\n",
       "      <td>1.025434e+02</td>\n",
       "      <td>25691.160000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575 -8.157366e-16  3.154853e-17 -4.409878e-15 -6.734811e-16   \n",
       "std     47488.145955  1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00   \n",
       "min         0.000000 -2.879855e+01 -4.403529e+01 -3.187173e+01 -4.013919e+00   \n",
       "25%     54201.500000 -4.698918e-01 -3.624707e-01 -5.872142e-01 -5.993788e-01   \n",
       "50%     84692.000000  9.245351e-03  3.965683e-02  1.186124e-01 -1.401724e-02   \n",
       "75%    139320.500000  6.716939e-01  4.867202e-01  6.774569e-01  5.250082e-01   \n",
       "max    172792.000000  1.253351e+00  1.335775e+01  6.187993e+00  1.191874e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -2.874435e-16  4.168992e-16 -8.767997e-16 -2.423604e-16  3.078727e-16   \n",
       "std    1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00   \n",
       "min   -8.240810e+01 -1.963606e+01 -3.520940e+01 -6.130252e+01 -1.222802e+01   \n",
       "25%   -5.010686e-01 -5.766822e-01 -4.478860e-01 -1.746805e-01 -5.853631e-01   \n",
       "50%   -3.936682e-02 -2.058046e-01  3.241723e-02  1.871982e-02 -4.681169e-02   \n",
       "75%    4.433465e-01  2.991625e-01  4.611107e-01  2.740785e-01  5.435305e-01   \n",
       "max    2.521413e+01  5.502015e+01  9.747824e+01  1.675153e+01  1.419494e+01   \n",
       "\n",
       "       ...           V20           V21           V22           V23  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  2.754870e-16  1.685077e-17  1.478472e-15 -6.797197e-16   \n",
       "std    ...  1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00   \n",
       "min    ... -7.069146e+01 -4.741907e+01 -1.506565e+01 -7.175446e+01   \n",
       "25%    ... -2.746334e-01 -3.109433e-01 -7.473476e-01 -2.591784e-01   \n",
       "50%    ... -8.104705e-02 -4.009429e-02  9.345377e-03 -1.792420e-02   \n",
       "75%    ...  1.725733e-01  2.537392e-01  7.283360e-01  2.364319e-01   \n",
       "max    ...  5.113464e+01  3.703471e+01  1.447304e+01  3.607668e+01   \n",
       "\n",
       "                V24           V25           V26           V27           V28  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   1.234659e-16 -7.659279e-16  3.247603e-16 -2.953495e-18  5.401572e-17   \n",
       "std    1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00   \n",
       "min   -4.683638e+00 -1.975033e+01 -5.401098e+00 -5.590660e+01 -4.674612e+01   \n",
       "25%   -5.854676e-01 -6.084001e-01 -6.780717e-01 -1.755053e-01 -1.604440e-01   \n",
       "50%    6.765678e-02  3.183240e-02 -1.081217e-01  3.325174e-03  3.406368e-02   \n",
       "75%    7.257153e-01  6.728006e-01  4.996663e-01  2.255648e-01  2.371526e-01   \n",
       "max    7.569684e+00  1.442532e+01  7.293975e+00  7.831940e+01  1.025434e+02   \n",
       "\n",
       "              Amount  \n",
       "count  284807.000000  \n",
       "mean       88.349619  \n",
       "std       250.120109  \n",
       "min         0.000000  \n",
       "25%         5.600000  \n",
       "50%        22.000000  \n",
       "75%        77.165000  \n",
       "max     25691.160000  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X[['V28']].boxplot(figsize = (12,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove outliers in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(X[X['V28'] > 60].index, inplace = True) #remove v3, v8, v19, v27, v28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Class'][X.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284800, 30)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284800,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199360, 30)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=300)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr = LogisticRegression(max_iter = 300)\n",
    "logr.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = logr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[85265    19]\n",
      " [   56   100]]\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85284\n",
      "           1       0.84      0.64      0.73       156\n",
      "\n",
      "    accuracy                           1.00     85440\n",
      "   macro avg       0.92      0.82      0.86     85440\n",
      "weighted avg       1.00      1.00      1.00     85440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print('\\n Classification Report:')\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "error_rate = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,10):\n",
    "    knn = KNeighborsClassifier(n_neighbors= i)\n",
    "    knn.fit(X_train, y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    error_rate.append(np.mean(pred_i != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb24f126040>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style('whitegrid')\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(range(1,10),error_rate, marker = 'o', markerfacecolor = 'red', markersize = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors= 2)\n",
    "knn.fit(X_train, y_train)\n",
    "pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[85284     0]\n",
      " [  143    13]]\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85284\n",
      "           1       1.00      0.08      0.15       156\n",
      "\n",
      "    accuracy                           1.00     85440\n",
      "   macro avg       1.00      0.54      0.58     85440\n",
      "weighted avg       1.00      1.00      1.00     85440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print('\\n Classification Report:')\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train, y_train)\n",
    "pred = dtree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[85255    29]\n",
      " [   36   120]]\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85284\n",
      "           1       0.81      0.77      0.79       156\n",
      "\n",
      "    accuracy                           1.00     85440\n",
      "   macro avg       0.90      0.88      0.89     85440\n",
      "weighted avg       1.00      1.00      1.00     85440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print('\\n Classification Report:')\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=150)\n",
    "rf.fit(X_train,y_train)\n",
    "rf_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[85276     8]\n",
      " [   34   122]]\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85284\n",
      "           1       0.94      0.78      0.85       156\n",
      "\n",
      "    accuracy                           1.00     85440\n",
      "   macro avg       0.97      0.89      0.93     85440\n",
      "weighted avg       1.00      1.00      1.00     85440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, rf_pred))\n",
    "print('\\n Classification Report:')\n",
    "print(classification_report(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[85284     0]\n",
      " [  156     0]]\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85284\n",
      "           1       0.00      0.00      0.00       156\n",
      "\n",
      "    accuracy                           1.00     85440\n",
      "   macro avg       0.50      0.50      0.50     85440\n",
      "weighted avg       1.00      1.00      1.00     85440\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print('\\n Classification Report:')\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.1,1,10,100,1000], 'gamma':[1,0.1,0.01,0.001,0.0001]}\n",
    "grid = GridSearchCV(SVC(), param_grid, verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV] C=0.1, gamma=1 ..................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... C=0.1, gamma=1, score=0.998, total= 7.2min\n",
      "[CV] C=0.1, gamma=1 ..................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  7.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... C=0.1, gamma=1, score=0.998, total= 7.8min\n",
      "[CV] C=0.1, gamma=1 ..................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 15.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... C=0.1, gamma=1, score=0.998, total= 7.4min\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ...................... C=0.1, gamma=1, score=0.998, total= 7.3min\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ...................... C=0.1, gamma=1, score=0.998, total= 7.1min\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] .................... C=0.1, gamma=0.1, score=0.998, total= 7.5min\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-3949096c802a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    864\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport_vectors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_support\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual_coef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_probA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             self._probB, self.fit_status_ = libsvm.fit(\n\u001b[0m\u001b[1;32m    269\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0msvm_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[84856   428]\n",
      " [   60    96]]\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     85284\n",
      "           1       0.18      0.62      0.28       156\n",
      "\n",
      "    accuracy                           0.99     85440\n",
      "   macro avg       0.59      0.81      0.64     85440\n",
      "weighted avg       1.00      0.99      1.00     85440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print('\\n Classification Report:')\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is a credit card fraud dataset where 0 is not fraud and 1 is fraud, it is assumed that the recall for class 1 and f1-score would be more relevant. Recall (TP/TP+FN) as we want to be able to predict more fraud cases and f1-score which places equal importance on both precision and recall.\n",
    "\n",
    "logistic regression: 0.64 0.73  \n",
    "knn:                           0.08  0.15                      \n",
    "decision tree:                 0.77  0.79    \n",
    "random forest:                 0.78  0.85  \n",
    "support vector classification: 0.00  0.00 (not enough computation power to perform grid search for hyper-parameter tuning for svm)  \n",
    "naives bayes:                  0.62  0.28\n",
    "\n",
    "Overall, best performing model would be random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
